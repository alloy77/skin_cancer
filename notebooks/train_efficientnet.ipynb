{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training EfficientNet B3 for Skin Cancer Detection\n",
    "\n",
    "This notebook contains the steps for training and fine-tuning the EfficientNet B3 model on the preprocessed skin lesion images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "\n",
    "First, we need to import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rikul\\.conda\\envs\\py310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py:37: UserWarning: A NumPy version >=1.23.5 and <2.5.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse  # pylint: disable=g-import-not-at-top\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B0 as EFNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import mixed_precision\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Directories\n",
    "\n",
    "Next, we define the directories for the processed data and the saved models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = r\"G:\\OneDrive\\ML-MinorProject\\ISIC-2020 Dataset\"\n",
    "PROCESSED_TRAIN_DIR = os.path.join(BASE_DIR, \"processed_train\")\n",
    "PROCESSED_VAL_DIR = os.path.join(BASE_DIR, \"processed_val\")\n",
    "PROCESSED_TEST_DIR = os.path.join(BASE_DIR, \"processed_test\")\n",
    "\n",
    "MODEL_DIR = r\"G:\\OneDrive\\ML-MinorProject\\models\"\n",
    "EFFICIENTNET_MODEL_PATH = os.path.join(MODEL_DIR, \"efficientnet\", \"efficientnet_best_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Processing Configurations\n",
    "\n",
    "We define the image processing configurations and create data generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26500 images belonging to 2 classes.\n",
      "Found 6626 images belonging to 2 classes.\n",
      "Found 10982 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (224, 224)  # EfficientNetB0 input size\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    PROCESSED_TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    PROCESSED_VAL_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    PROCESSED_TEST_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Data Augmentation\n",
    "\n",
    "We visualize some augmented images to ensure that the augmentations are applied correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     plt\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAugmented Images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 14\u001b[0m \u001b[43mvisualize_augmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m, in \u001b[0;36mvisualize_augmentation\u001b[1;34m(generator)\u001b[0m\n\u001b[0;32m      3\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(generator)\n\u001b[0;32m      4\u001b[0m images \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m7\u001b[39m):\n\u001b[0;32m      8\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m7\u001b[39m, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize some augmented images\n",
    "def visualize_augmentation(generator):\n",
    "    batch = next(generator)\n",
    "    images = batch[0]\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(7):\n",
    "        plt.subplot(1, 7, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(\"Augmented Images\")\n",
    "    plt.show()\n",
    "\n",
    "visualize_augmentation(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Enable Mixed Precision\n",
    "\n",
    "We enable mixed precision to improve training performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "Your GPU may run slowly with dtype policy mixed_float16 because it does not have compute capability of at least 7.0. Your GPU:\n",
      "  NVIDIA GeForce GTX 1050 Ti, compute capability 6.1\n",
      "See https://developer.nvidia.com/cuda-gpus for a list of GPUs and their compute capabilities.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    }
   ],
   "source": [
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Define and Compile Model\n",
    "\n",
    "We define and compile the EfficientNet B3 model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetv2-b0 (Function  (None, 7, 7, 1280)       5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,920,593\n",
      "Trainable params: 5,859,985\n",
      "Non-trainable params: 60,608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = EFNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid', dtype='float32')  # Ensure output is float32\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Define Callbacks\n",
    "\n",
    "We define callbacks to improve the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    EFFICIENTNET_MODEL_PATH,\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    mode=\"min\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [checkpoint, early_stopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train the Model\n",
    "\n",
    "We train the model using the data generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1657/1657 [==============================] - 2581s 2s/step - loss: 0.0559 - accuracy: 0.9833 - val_loss: 0.0746 - val_accuracy: 0.9826 - lr: 2.0000e-05\n",
      "Epoch 2/20\n",
      "1657/1657 [==============================] - 2590s 2s/step - loss: 0.0548 - accuracy: 0.9833 - val_loss: 0.0743 - val_accuracy: 0.9819 - lr: 2.0000e-05\n",
      "Epoch 3/20\n",
      "1657/1657 [==============================] - 2612s 2s/step - loss: 0.0538 - accuracy: 0.9832 - val_loss: 0.0748 - val_accuracy: 0.9814 - lr: 2.0000e-05\n",
      "Epoch 4/20\n",
      "1657/1657 [==============================] - 2523s 2s/step - loss: 0.0525 - accuracy: 0.9838 - val_loss: 0.0745 - val_accuracy: 0.9808 - lr: 2.0000e-05\n",
      "Epoch 5/20\n",
      "1657/1657 [==============================] - 2694s 2s/step - loss: 0.0495 - accuracy: 0.9846 - val_loss: 0.0771 - val_accuracy: 0.9784 - lr: 2.0000e-05\n",
      "Epoch 6/20\n",
      "1657/1657 [==============================] - 2538s 2s/step - loss: 0.0503 - accuracy: 0.9843 - val_loss: 0.0746 - val_accuracy: 0.9804 - lr: 2.0000e-05\n",
      "Epoch 7/20\n",
      "1657/1657 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9851\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "1657/1657 [==============================] - 2655s 2s/step - loss: 0.0475 - accuracy: 0.9851 - val_loss: 0.0868 - val_accuracy: 0.9751 - lr: 2.0000e-05\n",
      "Epoch 8/20\n",
      "1657/1657 [==============================] - 2703s 2s/step - loss: 0.0453 - accuracy: 0.9859 - val_loss: 0.0813 - val_accuracy: 0.9793 - lr: 4.0000e-06\n",
      "Epoch 9/20\n",
      "1657/1657 [==============================] - 2620s 2s/step - loss: 0.0459 - accuracy: 0.9851 - val_loss: 0.0797 - val_accuracy: 0.9789 - lr: 4.0000e-06\n",
      "Epoch 10/20\n",
      "1657/1657 [==============================] - 2674s 2s/step - loss: 0.0437 - accuracy: 0.9858 - val_loss: 0.0797 - val_accuracy: 0.9801 - lr: 4.0000e-06\n",
      "Epoch 11/20\n",
      "1657/1657 [==============================] - 2717s 2s/step - loss: 0.0432 - accuracy: 0.9857 - val_loss: 0.0822 - val_accuracy: 0.9795 - lr: 4.0000e-06\n",
      "Epoch 12/20\n",
      "1657/1657 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9852\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "1657/1657 [==============================] - 2856s 2s/step - loss: 0.0430 - accuracy: 0.9852 - val_loss: 0.0834 - val_accuracy: 0.9802 - lr: 4.0000e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Fine-Tune the Model\n",
    "\n",
    "We unfreeze the base model and fine-tune the entire model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1657/1657 [==============================] - 2746s 2s/step - loss: 0.0536 - accuracy: 0.9836 - val_loss: 0.0774 - val_accuracy: 0.9813 - lr: 1.0000e-05\n",
      "Epoch 2/10\n",
      "1657/1657 [==============================] - 2520s 2s/step - loss: 0.0519 - accuracy: 0.9841 - val_loss: 0.0755 - val_accuracy: 0.9804 - lr: 1.0000e-05\n",
      "Epoch 3/10\n",
      "1657/1657 [==============================] - 2688s 2s/step - loss: 0.0514 - accuracy: 0.9838 - val_loss: 0.0781 - val_accuracy: 0.9798 - lr: 1.0000e-05\n",
      "Epoch 4/10\n",
      "1657/1657 [==============================] - 2635s 2s/step - loss: 0.0503 - accuracy: 0.9838 - val_loss: 0.0773 - val_accuracy: 0.9799 - lr: 1.0000e-05\n",
      "Epoch 5/10\n",
      "1657/1657 [==============================] - 2760s 2s/step - loss: 0.0497 - accuracy: 0.9845 - val_loss: 0.0767 - val_accuracy: 0.9786 - lr: 1.0000e-05\n",
      "Epoch 6/10\n",
      "1657/1657 [==============================] - 2708s 2s/step - loss: 0.0479 - accuracy: 0.9847 - val_loss: 0.0776 - val_accuracy: 0.9817 - lr: 1.0000e-05\n",
      "Epoch 7/10\n",
      "1657/1657 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9849\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.9999999494757505e-06.\n",
      "1657/1657 [==============================] - 2720s 2s/step - loss: 0.0482 - accuracy: 0.9849 - val_loss: 0.0798 - val_accuracy: 0.9810 - lr: 1.0000e-05\n",
      "Epoch 8/10\n",
      "1657/1657 [==============================] - 2635s 2s/step - loss: 0.0472 - accuracy: 0.9849 - val_loss: 0.0812 - val_accuracy: 0.9808 - lr: 2.0000e-06\n",
      "Epoch 9/10\n",
      "1657/1657 [==============================] - 3035s 2s/step - loss: 0.0465 - accuracy: 0.9849 - val_loss: 0.0804 - val_accuracy: 0.9808 - lr: 2.0000e-06\n",
      "Epoch 10/10\n",
      "1657/1657 [==============================] - 2651s 2s/step - loss: 0.0473 - accuracy: 0.9846 - val_loss: 0.0788 - val_accuracy: 0.9795 - lr: 2.0000e-06\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "fine_tune_history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save the Final Model\n",
    "\n",
    "We save the final model after training and fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model saved to G:\\OneDrive\\ML-MinorProject\\models\\efficientnet\\efficientnet_final_model.h5\n"
     ]
    }
   ],
   "source": [
    "final_model_path = os.path.join(MODEL_DIR, \"efficientnet\", \"efficientnet_final_model.h5\")\n",
    "model.save(final_model_path)\n",
    "print(f\"Final model saved to {final_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
